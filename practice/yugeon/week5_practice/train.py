# ğŸ”§ train.py
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from model import CNN250514 # model.pyì—ì„œ ì‘ì„±í•œ CNN
from dataset import get_dataloaders250514
from utils import accuracy, save_model

def parse_args():
    parser = argparse.ArgumentParser(description='Train CNN on CIFAR-10')
    # í•™ìŠµ ì˜µì…˜ ì¶”ê°€
    parser.add_argument('--epochs', type=int, default=10, help='í•™ìŠµ ë°˜ë³µ ìˆ˜')
    parser.add_argument('--batch_size', type=int, default=64, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--lr', type=float, default=0.001, help='í•™ìŠµë¥ ')
    parser.add_argument('--num_workers', type=int, default=2, help='DataLoader ì›Œì»¤ ìˆ˜')
    parser.add_argument('--save_path', type=str, default='cnn.pth', help='ëª¨ë¸ ì €ì¥ ê²½ë¡œ')
    return parser.parse_args()


def train(args):
    """
    í•™ìŠµ íë¦„:
    1) ë””ë°”ì´ìŠ¤ ì„¤ì • (MPS > CPU)
    2) ëª¨ë¸, DataLoader, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
    3) ì—í­ ë£¨í”„: ìˆœì „íŒŒ â†’ ì†ì‹¤ ê³„ì‚° â†’ ì—­ì „íŒŒ â†’ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
    4) ì—í­ë³„ í‰ê·  ì†ì‹¤ ë° ì •í™•ë„ ì¶œë ¥
    5) ìµœì¢… ëª¨ë¸ ì €ì¥
    """
    # í•™ìŠµ ì†Œìš”ì‹œê°„ ì¸¡ì •
    import time
    start_time = time.time()

    # 1) ë””ë°”ì´ìŠ¤ ì„¤ì •: MPS ìš°ì„ , ì—†ìœ¼ë©´ CPU
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print("Using CUDA device")
    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():
        device = torch.device("mps")
        print("Using MPS device")
    else:
        device = torch.device("cpu")
        print("Using CPU device")

    # 2) ëª¨ë¸ ì´ˆê¸°í™”
    model = CNN250514().to(device)
    trainloader, testloader = get_dataloaders250514(batch_size=args.batch_size, num_workers=args.num_workers)
    # ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=args.lr)

    # 3) í•™ìŠµ ë£¨í”„
    for epoch in range(1, args.epochs + 1):
        model.train()
        epoch_loss, epoch_acc = 0.0, 0.0
        for inputs, labels in trainloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
            epoch_acc += accuracy(outputs, labels)

        # 4) ì—í­ë³„ í‰ê·  ê³„ì‚° ë° ë¡œê·¸ ì¶œë ¥
        avg_loss = epoch_loss / len(trainloader)
        avg_acc = epoch_acc / len(trainloader)
        print(f'Epoch [{epoch}/{args.epochs}] - Loss: {avg_loss:.4f}, Acc: {avg_acc:.4f}')

    # 5) ëª¨ë¸ ì €ì¥
    save_model(model, args.save_path)
    print(f'Model saved to {args.save_path}')

    # 6) í…ŒìŠ¤íŠ¸ë°ì´í„° ì ìˆ˜
    model.eval()
    test_acc = 0.0
    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            test_acc += accuracy(outputs, labels)

    # ì‹œê°„ ì¸¡ì • í›„ ì¶œë ¥
    elapsed_time = time.time() - start_time
    print(f"Total training time: {elapsed_time:.2f} seconds")
    print(f"Test Accuracy: {test_acc / len(testloader):.4f}")


if __name__ == '__main__':
    args = parse_args()
    train(args)


